/* SCE CONFIDENTIAL
 * PlayStation(R)Edge 1.2.0
 * Copyright (C) 2007 Sony Computer Entertainment Inc.
 * All Rights Reserved.
 */

#include "edge/libedgegeomtool/libedgegeomtool.h"
#include "edge/libedgegeomtool/libedgegeomtool_internal.h"

#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <float.h>
#include <limits.h>

#if defined(__PPU__) // on the PPU, we need cell/gcm.h to access GCM Measure mode
	#include <cell/gcm.h> // $CELL_SDK/target/common/include
#else
	#include <edge/edge_stdint.h>
	#if  _MSC_VER >= 1400
		#pragma warning( push )
		#pragma warning( disable : 4127 )		// constant conditional expression
		#pragma warning( disable : 4245 )		// int->uint32_t conversion
		#pragma warning( disable : 4333 )		// right shift too large; data loss
		#pragma warning( disable : 4311 )		// pointer truncation
		#pragma warning( disable : 4390 )		// empty conditional expression
		#pragma warning( disable : 4819 )		// The file contains a character that cannot be represented in the current code page (932)

		#if defined(WIN64) && !defined(WIN32)
			#define WIN32 // required for gcm_tool.h under WIN64, which tests for WIN32 directly
			#include <gcm_tool.h> // $CELL_SDK/host-common/include
			#undef WIN32
		#else
			#include <gcm_tool.h> // $CELL_SDK/host-common/include
		#endif

		#pragma warning( pop )
	#endif
#endif

/**
 * These buffer sizes limit the size of each segment generated by the Edge partitioner.
 * They can be tweaked based on the amount of SPU local store available for applications.
 * For reference, the 256 KB of SPU local store is divided as follows during an Edge job:
 * - Two I/O buffers: one for the currently running job, and one for DMAing the
 *   previous/next job's data) [default: 2*48 KB = 96 KB]
 * - One scratch buffer for the currently running job [default: 64 KB]
 * - The job's SPU code [depends on which features are enabled; currently ~48-64 KB]
 * - The SPU stack [default: 8 KB]
 * - SPURS kernel, policy module, etc. See SPURS Overview, Chapter 10.8 [default: 22 KB]
 *
 * It would be wise to tweak these values to suit your studio's needs in order to maximize
 * the memory available for each partition.  Basically, for every 2K you subtract from
 * kMaxSpuCodeSize, you can add 1K to kMaxIoBufferSize.
 */
static const uint32_t kMaxIoBufferSize = 48*1024;  // maximum size of all data sent to/from the SPU for a single EdgeGeom job
static const uint32_t kMaxSpuCodeSize = 64*1024;   // max size of user's job code
static const uint32_t kMaxSpursCodeSize = 22*1024; // size of SPURs kernel, job streamer, etc. (see SPURS Overview chapter 10.8)
static const uint32_t kMaxSpursStackSize = 8*1024;
// The maximum size of the scratch buffer is inferred from the above estimates.  In fact, the scratch buffer
// has no hard-coded global maximum size; it depends on the current job's actual I/O buffer size.  The only meaningful
// capacity is the sum total of a given job's IO buffer and scratch buffer.
static const uint32_t kMaxIoScratchTotalSize = 256*1024 // total size of SPU local store
	- kMaxSpursCodeSize  // ...minus size of SPURS kernel etc.
	- kMaxSpursStackSize // ...minus size of the SPURS user stack
	- kMaxSpuCodeSize    // ...minus size of the user's SPU code
	- kMaxIoBufferSize;  // ...minus size of the second copy of the I/O buffer (for streaming the previous/next job's data)

//-------------------
#if 0
// Dumps the contents of EdgeGeomPartitionerInput as C source code, to facilitate sending debug data to the Edge team
// in the unlikely event of partitioner problems.
static int DumpPartitionerInputToFile(const EdgeGeomPartitionerInput &input, const char *fileName)
{
#if defined(__PPU__)
	(void)input;
	(void)fileName;
	return -1; // Don't dump anything when partitioning on the PPU
#else
	FILE *f = fopen(fileName, "w");
	if (f == NULL)
	{
		fprintf(f, "ERROR: Edge partitioner could not open '%s' for debug output\n", fileName);
		return -1;
	}

	// m_triangleList -- also, keep track of the largest vertex index
	uint32_t largestVertexIndex = 0;
	fprintf(f, "static uint32_t s_debugTriangleList[%d] = {\n", input.m_numTriangles*3);
	for(uint32_t iTri=0; iTri<input.m_numTriangles; ++iTri)
	{
		fprintf(f, "\t%u, %u, %u,\n", input.m_triangleList[3*iTri+0], input.m_triangleList[3*iTri+1], input.m_triangleList[3*iTri+2]);
		if (input.m_triangleList[3*iTri+0] > largestVertexIndex)
			largestVertexIndex = input.m_triangleList[3*iTri+0];
		if (input.m_triangleList[3*iTri+1] > largestVertexIndex)
			largestVertexIndex = input.m_triangleList[3*iTri+1];
		if (input.m_triangleList[3*iTri+2] > largestVertexIndex)
			largestVertexIndex = input.m_triangleList[3*iTri+2];
	}
	fprintf(f, "};\n");
	// m_cacheOptimizerCallback and m_cacheOptimizerCallbackUserData -- we can only detect whether the default
	// callbacks are used, but that's still helpful.
	const char *cacheOptimizerCallbackName = "CustomCallback";
	const uint8_t *cacheOptimizerUserDataAsBytes = (const uint8_t*)input.m_cacheOptimizerUserData;
	uint32_t cacheOptimizerUserDataSize = 0;
	if (input.m_cacheOptimizerCallback == edgeGeomKCacheOptimizer)
	{
		cacheOptimizerCallbackName = "edgeGeomKCacheOptimizer";
		cacheOptimizerUserDataSize = sizeof(EdgeGeomKCacheOptimizerUserData);
	}
	else if (input.m_cacheOptimizerCallback == edgeGeomKCacheOptimizerHillclimber)
	{
		cacheOptimizerCallbackName = "edgeGeomKCacheOptimizerHillclimber";
		cacheOptimizerUserDataSize = sizeof(EdgeGeomKCacheOptimizerHillclimberUserData);
	}
	if (cacheOptimizerUserDataAsBytes != NULL && cacheOptimizerUserDataSize > 0)
	{
		fprintf(f, "uint8_t s_debugCacheOptimizerUserDataBytes[] = {\n");
		for(uint32_t iByte=0; iByte<cacheOptimizerUserDataSize; ++iByte)
			fprintf(f, "\t0x%02X,\n", cacheOptimizerUserDataAsBytes[iByte]);
		fprintf(f, "};\n");
	}
	else 
	{
		fprintf(f, "uint8_t *s_debugCacheOptimizerUserDataBytes = NULL;\n");
	}

	// m_triangleCentroids -- output as integers to maintain bit-for-bit accuracy
	if (input.m_triangleCentroids != NULL)
	{
		fprintf(f, "static uint32_t s_debugTriangleCentroids[%d] = {\n", input.m_numTriangles*3);
		const uint32_t *centroidsAsInts = (const uint32_t*)input.m_triangleCentroids;
		for(uint32_t iTri=0; iTri<input.m_numTriangles; ++iTri)
		{
			fprintf(f, "\t0x%08X, 0x%08X, 0x%08X, // %ff, %ff, %ff,\n",
				centroidsAsInts[3*iTri+0], centroidsAsInts[3*iTri+1], centroidsAsInts[3*iTri+2],
				input.m_triangleCentroids[3*iTri+0], input.m_triangleCentroids[3*iTri+1], input.m_triangleCentroids[3*iTri+2]);
		}
		fprintf(f, "};\n");
	}
	else
	{
		fprintf(f, "static uint32_t *s_debugTriangleCentroids = NULL;\n");
	}
	// m_skinningMatrixIndexesPerVertex
	if (input.m_skinningMatrixIndexesPerVertex != NULL)
	{
		fprintf(f, "static int32_t s_debugSkinningMatrixIndexesPerVertex[%d] = {\n", (largestVertexIndex+1)*kEdgeGeomNumInputBonesPerVertex);
		for(uint32_t iVert=0; iVert<=largestVertexIndex; ++iVert)
		{
			fprintf(f, "\t");
			for(uint32_t iBone=0; iBone<kEdgeGeomNumInputBonesPerVertex; ++iBone)
			{
				fprintf(f, "%d, ", input.m_skinningMatrixIndexesPerVertex[kEdgeGeomNumInputBonesPerVertex*iVert+iBone]);
			}
			fprintf(f, "\n");
		}
		fprintf(f, "};\n");
	}
	else
	{
		fprintf(f, "static int32_t *s_debugSkinningMatrixIndexesPerVertex = NULL;\n");
	}
	// m_blendedVertexIndexes
	if (input.m_blendedVertexIndexes != NULL)
	{
		fprintf(f, "static float s_debugBlendedVertexIndexes[%d] = {\n", input.m_numBlendedVertexes);
		for(uint32_t iBlendVert=0; iBlendVert<input.m_numBlendedVertexes; ++iBlendVert)
			fprintf(f, "\t%u,\n", input.m_blendedVertexIndexes[iBlendVert]);
		fprintf(f, "};\n");
	}
	else
	{
		fprintf(f, "static uint32_t *s_debugBlendedVertexIndexes = NULL;\n");
	}

	// Misc. values that affect the partitioner
	fprintf(f, "// kMaxIoBufferSize       = %6d\n", kMaxIoBufferSize);
	fprintf(f, "// kMaxSpuCodeSize        = %6d\n", kMaxSpuCodeSize);
	fprintf(f, "// kMaxSpursCodeSize      = %6d\n", kMaxSpursCodeSize);
	fprintf(f, "// kMaxSpursStackSize     = %6d\n", kMaxSpursStackSize);
	fprintf(f, "// kMaxIoScratchTotalSize = %6d\n", kMaxIoScratchTotalSize);

	// EdgeGeomPartitionerInput
	fprintf(f, "EdgeGeomPartitionerInput debugPartitionerInput = {\n");
	fprintf(f, "\t%u, // m_numTriangles\n", input.m_numTriangles);
	fprintf(f, "\ts_debugTriangleList, // m_triangleList\n");
	fprintf(f, "\t%u, // m_numInputAttributes\n", input.m_numInputAttributes);
	fprintf(f, "\t%u, // m_numOutputAttributes\n", input.m_numOutputAttributes);
	fprintf(f, "\t{%u,%u}, // m_inputVertexStride\n", input.m_inputVertexStride[0], input.m_inputVertexStride[1]);
	fprintf(f, "\t%u, // m_outputVertexStride\n", input.m_outputVertexStride);
	fprintf(f, "\t(EdgeGeomSkinningFlavor)%u, // m_skinningFlavor\n", input.m_skinningFlavor);
	fprintf(f, "\t(EdgeGeomIndexesFlavor)%u, // m_indexListFlavor\n", input.m_indexListFlavor);
	fprintf(f, "\t(EdgeGeomMatrixFormat)%u, // m_skinningMatrixFormat\n", input.m_skinningMatrixFormat);
	fprintf(f, "\t%s, // m_cacheOptimizerCallback\n", cacheOptimizerCallbackName);
	fprintf(f, "\t(void*)s_debugCacheOptimizerUserDataBytes, // m_cacheOptimizerUserData\n", cacheOptimizerUserDataAsBytes);
	fprintf(f, "\t(EdgeGeomCustomPartitionDataSizeFunc)0x%p, // m_customDataSizeCallback -- TODO: set me appropriately!\n", input.m_customDataSizeCallback);
	fprintf(f, "\t(float*)s_debugTriangleCentroids, // m_triangleCentroids\n");
	fprintf(f, "\ts_debugSkinningMatrixIndexesPerVertex, // m_skinningMatrixIndexesPerVertex\n");
	fprintf(f, "\t%u, // m_deltaStreamVertexStride\n", input.m_deltaStreamVertexStride);
	fprintf(f, "\ts_debugBlendedVertexIndexes, // m_blendedVertexIndexes\n");
	fprintf(f, "\t%u, // m_numBlendedVertexes\n", input.m_numBlendedVertexes);
	fprintf(f, "\t(EdgeGeomCustomCommandBufferHoleSizeFunc)0x%p, // m_customCommandBufferHoleSizeCallback -- TODO: set me appropriately!\n", input.m_customCommandBufferHoleSizeCallback);
	fprintf(f, "};\n\n");

	fclose(f);
	return 0;
#endif // defined(__PPU__)
}
#endif

// Used for internal stat-tracking, to see how often ScoreTriangle() is called.
static uint32_t g_regularScoreCount = 0; // All calls
static uint32_t g_exactScoreCount = 0; // only calls where exactCalc == true

void edgeGeomComputeTriangleCentroids(const float *vertexes, uint32_t numFloatsPerVertex, uint16_t positionAttributeIndex,
								  const uint32_t *triangles, uint32_t numTriangles, float **outTriangleCentroids)
{
	if (numTriangles == 0)
	{
		*outTriangleCentroids = NULL;
		return;
	}

	*outTriangleCentroids = (float*)edgeGeomAlloc(numTriangles*3*sizeof(float));
	const float ONE_THIRD = 1.0f/3.0f;
	for (uint32_t iTri=0; iTri<numTriangles; iTri++)
	{
		// clear the face position initially
		const uint32_t destIndex = iTri*3;
		(*outTriangleCentroids)[destIndex+0] = 0;
		(*outTriangleCentroids)[destIndex+1] = 0;
		(*outTriangleCentroids)[destIndex+2] = 0;

		// then add each vertex position/3 to the face position
		for (uint32_t iVert=0; iVert<3; iVert++)
		{
			// calculate where the source position attributes are stored in the geometry unit for this vertex
			const uint32_t posIndex = numFloatsPerVertex * triangles[iTri*3+iVert] + positionAttributeIndex;
			(*outTriangleCentroids)[destIndex+0] += vertexes[posIndex+0] * ONE_THIRD;
			(*outTriangleCentroids)[destIndex+1] += vertexes[posIndex+1] * ONE_THIRD;
			(*outTriangleCentroids)[destIndex+2] += vertexes[posIndex+2] * ONE_THIRD;
		}
	}
}

//-------------------

void edgeGeomGetBlendedVertexes(const float *vertexDeltas, uint32_t numVertexes, uint32_t numFloatsPerDelta, const EdgeGeomSpuVertexFormat& deltaFormat,
									  const uint16_t *blendedAttributeIndexes, const EdgeGeomAttributeId *blendedAttributeIds, uint8_t numBlendedAttributes,
									  uint32_t numBlendShapes, const uint32_t *triangles, uint32_t numTriangles,
									  uint32_t **outBlendedVertexIndexes, uint32_t *outNumBlendedVertexes)
{
	if (numTriangles == 0)
	{
		*outBlendedVertexIndexes = NULL;
		*outNumBlendedVertexes = 0;
		return;
	}

	*outBlendedVertexIndexes = (uint32_t*)edgeGeomAlloc(numTriangles*3*sizeof(uint32_t));
	memcpy(*outBlendedVertexIndexes, triangles, numTriangles*3*sizeof(uint32_t));
	uint32_t numUniqueVertexIndexes = _edgeGeomSortUniqueArrayUnsigned(*outBlendedVertexIndexes, numTriangles*3);

	// these are the iterators for the output array
	uint32_t numFound = 0;
	
	// walk the unique index list and check each index for a non-zero blend shape delta.
	// we store the blended indexes in-place in the beginning of the array.
	for (uint32_t iIndex=0; iIndex<numUniqueVertexIndexes; iIndex++)
	{
		// cache the vertex's index while we walk through all the blended attributes
		const uint32_t vertexIndex = (*outBlendedVertexIndexes)[iIndex];
		// Check each blend shape in sequence
		for (uint32_t iBlendShape=0; iBlendShape<numBlendShapes; iBlendShape++)
		{
			const float *shape = vertexDeltas + iBlendShape * numVertexes * numFloatsPerDelta;

			for (uint32_t iAttr=0; iAttr<deltaFormat.m_numAttributes; iAttr++)
			{
				const EdgeGeomAttributeId attrId = deltaFormat.m_attributeDefinition[iAttr].m_attributeId;

				// Find the corresponding blended attribute in the delta stream
				bool foundSceneAttribute = false;
				uint16_t sceneAttrIndex = 0;
				for(uint32_t iSceneAttr=0; iSceneAttr<numBlendedAttributes; ++iSceneAttr)
				{
					if (blendedAttributeIds[iSceneAttr] != attrId)
						continue;
					sceneAttrIndex = blendedAttributeIndexes[iSceneAttr];
					foundSceneAttribute = true;
					break;
				}
				EDGEASSERT(foundSceneAttribute);

				// check for ANY non-zero floats.  As soon as we find one non-zero delta for an index,
				// we can add it to the list of blended vertexes and move on to the next index.
				const float *deltaAttr = shape + numFloatsPerDelta*vertexIndex + sceneAttrIndex;
				uint32_t const floatCount = deltaFormat.m_attributeDefinition[iAttr].m_count;
				for (uint32_t iCnt=0; iCnt<floatCount; iCnt++)		
				{
					if (deltaAttr[iCnt] != 0)
					{
						// add this index to the output list
						(*outBlendedVertexIndexes)[numFound++] = vertexIndex;
						goto ISBLENDSHAPING;
					}
				}
			}
		}
ISBLENDSHAPING:;  // they REALLY need to add multi-level breaks to C++
	}

	*outNumBlendedVertexes = numFound;
}

//-------------------

/// Determines the maximum space required in the RSX command buffer by a given Edge job.
uint32_t edgeGeomGetCommandBufferHoleSize(uint32_t numOutputAttributes, uint32_t numIndexes, EdgeGeomCustomCommandBufferHoleSizeFunc customHoleSizeCallback /*=0*/)
{
#if defined(_MSC_VER) && _MSC_VER < 1400
	// Visual Studio 2003 and earlier can't handle the gcm_tool.h header which defined all the
	// GCM Measure-mode functions, so we must fall back on the old cryptic hard-coded expression
	// for hole size calculations.  This is extremely regrettable.

	// command buffer hole is 16 bytes per attribute, plus enough space for potential RSX label writes
	// and vertex cache invalidation, plus the draw command (as a function of the index count), plus
	// enough space for all the padding required by local stall synchronization, aligned to 16 bytes.
	const uint32_t commandBufferHoleSize = (16*numOutputAttributes + 88 + ((numIndexes + 383) / 48) + 15) & ~15;
	return commandBufferHoleSize;
#else
	// Start with a fake GCM command context.  The GCM Measure-mode commands only increment the current
	// pointer without writing any data or doing any bounds checking, so we can just zero out the structure
	// to begin with.
	cell::Gcm::CellGcmContext fakeGcmContext;
	fakeGcmContext.current = fakeGcmContext.begin = fakeGcmContext.end = 0 ;

	// Every vertex attribute pointer will need to be set
	for(uint32_t iAttr=0; iAttr<numOutputAttributes; ++iAttr)
	{
		cell::Gcm::MeasureInline::cellGcmSetVertexDataArray(&fakeGcmContext, 0, 0, 0, 0, 0, 0, 0);
	}
	// If the main ring buffer is detected to have wrapped, we'll need to invalidate the vertex cache
	cell::Gcm::MeasureInline::cellGcmSetInvalidateVertexCache(&fakeGcmContext);
	// It's possible we'll need to to write an RSX label for each ring buffer
	const uint32_t numRingBuffers = 1;
	for(uint32_t iRingBuffer=0; iRingBuffer<numRingBuffers; ++iRingBuffer)
	{
		cell::Gcm::MeasureInline::cellGcmSetWriteTextureLabel(&fakeGcmContext, 0, 0);
	}
	// Reserve room for the job's draw call, assuming every single triangle is drawn (e.g. if culling is disabled)
	// The size of this command depends on both the number of indexes drawn and their alignment.  Passing 0x7E
	// (decimal 126) as the start of the index buffer generates the worst-case (largest) command size.
	cell::Gcm::MeasureInline::cellGcmSetDrawIndexArray(&fakeGcmContext, CELL_GCM_PRIMITIVE_TRIANGLES,
		numIndexes, CELL_GCM_DRAW_INDEX_ARRAY_TYPE_16, CELL_GCM_LOCATION_MAIN, 0x7E);

	// Reserve room for any additional commands specified by the user
	// The callback should probably take some TBD user data arguments
	if (customHoleSizeCallback != 0)
	{
		customHoleSizeCallback(&fakeGcmContext);
	}

	// For every 128 bytes of command data (rounded up), we add an additional 4 bytes to allow for padding,
	// since no command will be allowed to straddle a 128-byte boundary.
	uint32_t tempCommandBufferHoleSize = (uint32_t)((int8_t*)fakeGcmContext.current - (int8_t*)fakeGcmContext.begin);
	uint32_t localStallCount = ((tempCommandBufferHoleSize + 127) & ~127) / 128; 
	cell::Gcm::MeasureInline::cellGcmSetNopCommand(&fakeGcmContext, localStallCount);
	// It's possible that the extra padding causes us to cross another 128-byte boundary.
	// If so, we need to add one more Nop command.
	uint32_t tempCommandBufferHoleSize2 = (uint32_t)((int8_t*)fakeGcmContext.current - (int8_t*)fakeGcmContext.begin);
	uint32_t localStallCount2 = ((tempCommandBufferHoleSize2 + 127) & ~127) / 128;
	if (localStallCount2 != localStallCount)
	{
		cell::Gcm::MeasureInline::cellGcmSetNopCommand(&fakeGcmContext, 1);
	}

	// Return the final hole size
	uint32_t finalHoleSize = (uint32_t)((int8_t*)fakeGcmContext.current - (int8_t*)fakeGcmContext.begin);
	finalHoleSize = (finalHoleSize+0xF) & ~0xF; // round up to an even number of quads

	EDGEASSERT(finalHoleSize < 256*16);  // if this exceeds 8 bits after >>4, it won't fit in the byte allocated for it in EdgeGeomSpuConfigInfo
	return finalHoleSize;
#endif
}

//-------------------

// Contains all data necessary to remove the most recently added triangle from the current partition,
// if it is deemed that the partition has inadvertantly grown too big due to index compression.
struct EdgeGeomTriangleUndoData
{
	uint32_t m_triangleIndex; // Triangle index in the main triangle list
	float m_partitionCentroid[3]; // centroid value before this triangle was added
	uint32_t m_newVertexes[3]; // new vertex indexes added to the partition by this triangle.  Has m_numNewVertexes valid entries.
	int32_t m_newMatrices[12]; // new matrix indexes added to the matrition by this triangle's verts.  Has m_numNewMatrices valid entries.
	uint16_t m_numNewVertexes; // 0-3
	uint16_t m_numNewBlendedVertexes; // 0-3, <= m_numNewVertexes
	uint16_t m_numNewMatrices; // 0-12
};

struct EdgeGeomPartitionerContext
{
	uint32_t m_highestVertexIndex;
	int32_t m_highestMatrixIndex;
	uint32_t *m_adjacencyDataStarts;
	uint32_t *m_adjacentTrianglesPerVertex;
	int8_t   *m_triangleIsAvailable;
	uint32_t m_numOutputBonesPerVertex;
	// Keeps track of which elements (triangles, vertexes, etc.) are
	// in the partition currently being built.
	uint32_t m_numTrianglesLeft;
	uint32_t m_numTrianglesInPartition;
	uint32_t m_numVertexesInPartition;
	uint32_t m_numMatricesInPartition;
	uint32_t m_numBlendedVertexesInPartition;
	uint32_t *m_trianglesInPartition;
	uint32_t *m_vertexesInPartition;
	int32_t *m_matricesInPartition;
	float m_partitionCentroid[3];
	// Used in the index compression section of ScoreTriangle to
	// store results between calls
	uint32_t m_lastExactIndexesSize;
	uint32_t m_lastExactIndexesTempSize;
	uint32_t m_lastNumTriangles;
	// Stack of recently-added triangles info, in case we need to remove them later.
	// The stack is cleared every time an exact test is performed and the partition is
	// deemed to fit safely.
	EdgeGeomTriangleUndoData *m_triangleUndoStack;
	uint32_t m_triangleUndoStackCapacity; // Maximum number of elements in the triangle undo stack
	uint32_t m_triangleUndoStackTop; // Index of the current top of the stack

	// The most recent valid (<=1.0f) scores for this partition.  For stat-keeping purposes only,
	// if users are curious about which buffer is limiting their final partition size.
	float m_lastInOutScore;
	float m_lastScratchScore;
	float m_lastBlendShapeScore;
	float m_lastIndexesScore;
};

//-------------------
// Helper functions go here.
//-------------------

/// This function figures out how big of an array we need to set aside
/// for vertex-related data.
static uint32_t FindHighestVertexIndex(const uint32_t *triangleList, uint32_t numTriangles)
{
	uint32_t highest = 0;
	const uint32_t numIndexes = numTriangles*3;
	for (uint32_t i=0; i<numIndexes; i++)
	{
		if (triangleList[i] > highest)
		{
			highest = triangleList[i];
		}
	}
	return highest;
}

//-------------------
/// This function figures out how big of an array to set aside for
/// matrix-related data.  MAY BE -1 IF NOT SKINNED!
static int32_t FindHighestMatrixIndex(const uint32_t *triangleList, uint32_t numTriangles, const int32_t *matricesPerVertex)
{
	// Notice, this function *could* have been written in terms of the
	// highest vertex index, but was not because in the event the user
	// has a huge database of vertexes, but the partitions are
	// only using small subsets of the total set, this will be much
	// faster and use less memory by selecting the lowest matrix index
	// *in use* by the triangle list, rather than the highest
	// described by the vertex data.
	int32_t highest = -1;

	if (matricesPerVertex == NULL)
		return highest;

	const uint32_t numIndexes = numTriangles*3;
	for (uint32_t i=0; i<numIndexes; i++)
	{
		const uint32_t offsetToVertexData = triangleList[i]*kEdgeGeomNumInputBonesPerVertex;
		for (uint32_t j=0; j<kEdgeGeomNumInputBonesPerVertex; j++)
		{
			if (matricesPerVertex[offsetToVertexData + j] > highest)
			{
				highest = matricesPerVertex[offsetToVertexData + j];
			}
		}
	}
	return highest;
}

//-------------------
/// This function walks all the triangles and constructs a quick
/// lookup that goes from vertex to triangles it is contained within.
static void FindAdjacentTriangles(EdgeGeomPartitionerContext &context, uint32_t *triangleList, uint32_t numTriangles)
{
	const uint32_t numIndexes = numTriangles*3;
	const uint32_t numVertexes = context.m_highestVertexIndex; // not a count of unique vertexes -- just the highest vertex index used

	// Okay, let's make some auxiliary data structures so we can find
	// adjacencies easily.
	context.m_adjacencyDataStarts = (uint32_t*)edgeGeomAlloc((numVertexes+2)*sizeof(uint32_t)); // one extra to get rid of the 'last element' special case.
	context.m_adjacentTrianglesPerVertex = (uint32_t*)edgeGeomAlloc(numIndexes*sizeof(uint32_t));

	// first, clear the data structures to zero or invalid
	memset(context.m_adjacencyDataStarts, 0, (numVertexes+2)*sizeof(uint32_t));
	memset(context.m_adjacentTrianglesPerVertex, 0xff, numIndexes*sizeof(uint32_t));

	// now, walk each index in the triangle list and add up how many
	// times we see each one.  This first pass is quick.
	for (uint32_t i=0; i<numIndexes; ++i)
	{
		// this is off by one, so that [0]==0, and [1] is the # of
		// times 0 was seen.  This makes summing them simpler.
		context.m_adjacencyDataStarts[triangleList[i]+1]++;
	}

	// Rewrite the adjacencyDataStarts so it is an offset into the
	// adjacentTrianglesPerVertex array, such that
	// adjacencyDataStarts[N] is the index where vertex N's triangle
	// indexes begin, and adjacencyDataStarts[N+1] are where the next
	// one begins.
	for (uint32_t i=1; i<numVertexes+2; ++i)
	{
		context.m_adjacencyDataStarts[i] += context.m_adjacencyDataStarts[i-1];
	}

	// Finally, walk the triangle list one last time and insert the
	// triangle indexes into their respective sub-arrays.
	for (uint32_t i=0; i<numIndexes; i++)
	{
		const uint32_t vertexIndex = triangleList[i];

		uint32_t unusedSlot = context.m_adjacencyDataStarts[vertexIndex];
		for (; unusedSlot < context.m_adjacencyDataStarts[vertexIndex+1]; ++unusedSlot)
		{
			if (context.m_adjacentTrianglesPerVertex[unusedSlot]==0xffffffff)  // use this empty slot
				break;
		}
		EDGEASSERT(unusedSlot < context.m_adjacencyDataStarts[vertexIndex+1]);

		// store the triangle number in this vertex's adjacent face list
		context.m_adjacentTrianglesPerVertex[unusedSlot] = i/3;
	}
}

//-------------------
// If triangleCentroids is provided (non-NULL), this function actually
// finds the NEAREST available triangle, to compact partitions
// spatially. This provides slightly superior results to just finding
// the first available triangle in the list.
static int32_t FindFirstAvailableTriangle(EdgeGeomPartitionerContext &context, uint32_t numTriangles, const float *triangleCentroids)
{
	// If we don't have triangle centroids, just find the first
	// available triangle in the list.
	int32_t bestTriangle = -1;
	if (triangleCentroids == NULL)
	{
		for(uint32_t iTri = 0; iTri<numTriangles; ++iTri)
		{
			if (context.m_triangleIsAvailable[iTri])
			{
				bestTriangle = iTri;
				break;
			}
		}
		return bestTriangle;
	}

	// If we have triangle centroids, but the partition is empty, then choose the triangle with the centroid
	// closest to negative infinity.  This helps ensure that the partitioner starts at some extreme of the object, 
	if (context.m_numTrianglesInPartition == 0)
	{
		float smallestCentroid[3] = {FLT_MAX, FLT_MAX, FLT_MAX};
		for(uint32_t iTri=0; iTri<numTriangles; ++iTri)
		{
			if (!context.m_triangleIsAvailable[iTri])
				continue;
			if (triangleCentroids[iTri*3+0] < smallestCentroid[0] &&
				triangleCentroids[iTri*3+1] < smallestCentroid[1] &&
				triangleCentroids[iTri*3+2] < smallestCentroid[2])
			{
				smallestCentroid[0] = triangleCentroids[iTri*3+0];
				smallestCentroid[1] = triangleCentroids[iTri*3+1];
				smallestCentroid[2] = triangleCentroids[iTri*3+2];
				bestTriangle = iTri;
			}
		}
		return bestTriangle;
	}

	// Search for the closest available triangle to the partition's centroid
	float minDistanceSq = FLT_MAX;
	for (uint32_t iTri = 0; iTri<numTriangles; iTri++)
	{
		if (!context.m_triangleIsAvailable[iTri])  // check to see if it's the closest triangle we've found yet
			continue;

		const float deltaX = (triangleCentroids[iTri*3+0] - context.m_partitionCentroid[0]);
		const float deltaY = (triangleCentroids[iTri*3+1] - context.m_partitionCentroid[1]);
		const float deltaZ = (triangleCentroids[iTri*3+2] - context.m_partitionCentroid[2]);
		const float distanceSq = deltaX*deltaX + deltaY*deltaY + deltaZ*deltaZ;
		if (distanceSq<minDistanceSq)
		{
			minDistanceSq = distanceSq;
			bestTriangle = iTri;
		}
	}
	return bestTriangle;
}

//-------------------
static void AssignTriangleToPartition(EdgeGeomPartitionerContext &context, uint32_t triangleIndex, const uint32_t *triangleList, const int32_t *matricesPerVertex,
									  const uint32_t *blendedVertexIndexes, uint32_t numBlendedVertexes, const float *triangleCentroids)
{
	EDGEASSERT(context.m_triangleIsAvailable[triangleIndex]==1);

	// push a new entry to the top of the triangle undo stack
	EDGEASSERT(context.m_triangleUndoStackTop < context.m_triangleUndoStackCapacity);
	EdgeGeomTriangleUndoData &undoData = context.m_triangleUndoStack[ context.m_triangleUndoStackTop++ ];
	memset(&undoData, 0, sizeof(EdgeGeomTriangleUndoData));
	undoData.m_triangleIndex = triangleIndex;

	// Store the current centroid
	undoData.m_partitionCentroid[0] = context.m_partitionCentroid[0];
	undoData.m_partitionCentroid[1] = context.m_partitionCentroid[1];
	undoData.m_partitionCentroid[2] = context.m_partitionCentroid[2];

	if (triangleCentroids != NULL)
	{
		// to update a centroid, you have to multiply up the average, add
		// your new point, then divide it back down again
		
		// numerically robust centroid update 
        float num = (float)context.m_numTrianglesInPartition; 
        float f = num / (num + 1.0f), g = 1.0f / (num + 1.0f); 
        context.m_partitionCentroid[0] = context.m_partitionCentroid[0] * f + triangleCentroids[triangleIndex*3+0] * g; 
        context.m_partitionCentroid[1] = context.m_partitionCentroid[1] * f + triangleCentroids[triangleIndex*3+1] * g; 
        context.m_partitionCentroid[2] = context.m_partitionCentroid[2] * f + triangleCentroids[triangleIndex*3+2] * g; 
	}

	// add the triangle to the end of the triangle list for this partition
	uint32_t *newTriangle = context.m_trianglesInPartition + context.m_numTrianglesInPartition*3;
	newTriangle[0] = triangleList[triangleIndex*3+0];
	newTriangle[1] = triangleList[triangleIndex*3+1];
	newTriangle[2] = triangleList[triangleIndex*3+2];
	++context.m_numTrianglesInPartition;
	--context.m_numTrianglesLeft;
	context.m_triangleIsAvailable[triangleIndex] = 0;

	// Now, we need to figure out if the vertexes in this triangle
	// have been added to this partition before or not.  Easiest way
	// to do it is to binary search the vertexesInPartition array
	// three times.  If any are not found, add them to the end, then
	// quicksort them into place.
	uint32_t numVertexesAdded = 0;
	for (uint32_t i=triangleIndex*3; i<triangleIndex*3+3; i++)
	{
		void *wasFound = bsearch(&triangleList[i], context.m_vertexesInPartition, context.m_numVertexesInPartition, sizeof(uint32_t), _edgeGeomIsEqualUnsigned);
		if (wasFound)
			continue;

		// check the 'new' vertex indexes at the end of the list, since it's possible a 
		// degenerate face may have two indexes that are equal AND new to the partition.
		// In this case, we only want to add the vertex once.
		bool duplicate = false;
		for (uint32_t k=context.m_numVertexesInPartition; k<context.m_numVertexesInPartition+numVertexesAdded; k++)
		{
			if (context.m_vertexesInPartition[k]==triangleList[i])
			{
				duplicate = true;
				break;
			}
		}

		if (duplicate)
			continue;

		// add this vertex to the list (past the sorted portion)
		context.m_vertexesInPartition[context.m_numVertexesInPartition + numVertexesAdded] = triangleList[i];  
		numVertexesAdded++;
		undoData.m_newVertexes[ undoData.m_numNewVertexes++ ] = triangleList[i];

		// finally, check to see if this newly added vertex
		// will be blending or not. If the blend shape
		// flavor is non-null and no list of blending
		// verts is supplied, assume ALL are blending if
		// there is a blend shape flavor, and NONE are
		// blending if there is no blend shape flavor.
		if (blendedVertexIndexes && bsearch(triangleList+i, blendedVertexIndexes, numBlendedVertexes, sizeof(uint32_t), _edgeGeomIsEqualUnsigned))
		{
			// the partitioner only needs to know that at
			// least one vertex is blending.  We keep a
			// count for ease of debugging.
			context.m_numBlendedVertexesInPartition++;
			undoData.m_numNewBlendedVertexes++;
		}				
	}

	// resort the array so the searches work next time around, if needed
	if (numVertexesAdded)
	{
		context.m_numVertexesInPartition += numVertexesAdded;
		qsort(context.m_vertexesInPartition, context.m_numVertexesInPartition, sizeof(uint32_t), _edgeGeomIsEqualUnsigned);
	}

	// Similarly, do this for matrices.  But, each VERTEX of the
	// triangle has multiple matrices, so it's a double-nested loop.
	if (context.m_matricesInPartition)
	{
		uint32_t numMatricesAdded = 0;
		for (uint32_t iVertex=0; iVertex<3; ++iVertex)                  // per vertex in the triangle
		{
			uint32_t vertexIndex = newTriangle[iVertex];
			for (uint32_t iVertMatrix=vertexIndex*kEdgeGeomNumInputBonesPerVertex;
				iVertMatrix<vertexIndex*kEdgeGeomNumInputBonesPerVertex+kEdgeGeomNumInputBonesPerVertex; ++iVertMatrix)  // per matrix of the vertex in the triangle
			{
				if (matricesPerVertex[iVertMatrix] == -1)                               // ignore the "not used" entries
					continue;

				void *wasFound = bsearch(&matricesPerVertex[iVertMatrix], context.m_matricesInPartition, context.m_numMatricesInPartition, sizeof(int32_t), _edgeGeomIsEqualInt);
				if (wasFound)
					continue;

				// check the 'new' matrices at the end of the
				// list, since it's possible the same matrix
				// may be added multiple times by the same
				// triangle
				bool duplicate = false;
				for (uint32_t iPartitionMatrix=context.m_numMatricesInPartition; iPartitionMatrix<context.m_numMatricesInPartition+numMatricesAdded; ++iPartitionMatrix)
				{
					if (context.m_matricesInPartition[iPartitionMatrix]==matricesPerVertex[iVertMatrix])
					{
						duplicate = true;
						break;
					}
				}

				if (!duplicate)
				{
					// add this matrix to the list (past the sorted portion)
					context.m_matricesInPartition[context.m_numMatricesInPartition + numMatricesAdded] = matricesPerVertex[iVertMatrix];  
					numMatricesAdded++;
					undoData.m_newMatrices[ undoData.m_numNewMatrices++ ] = matricesPerVertex[iVertMatrix];
				}
			}
		}

		if (numMatricesAdded)  // resort the matrices if some were added
		{
			context.m_numMatricesInPartition += numMatricesAdded;
			qsort(context.m_matricesInPartition, context.m_numMatricesInPartition, sizeof(int32_t), _edgeGeomIsEqualInt);
		}
	}
}

static bool RemoveLastTriangleFromPartition(EdgeGeomPartitionerContext &context)
{
	// Make sure there's a triangle to remove
	if (context.m_triangleUndoStackTop == 0)
		return false;
	const EdgeGeomTriangleUndoData &undoData = context.m_triangleUndoStack[--context.m_triangleUndoStackTop];
	EDGEASSERT(context.m_triangleIsAvailable[undoData.m_triangleIndex] == 0);

	// Restore the previous centroid value
	context.m_partitionCentroid[0] = undoData.m_partitionCentroid[0];
	context.m_partitionCentroid[1] = undoData.m_partitionCentroid[1];
	context.m_partitionCentroid[2] = undoData.m_partitionCentroid[2];

	// Remove the indexes from the end of the partition's triangle list, and mark it as available again.
	--context.m_numTrianglesInPartition;
	++context.m_numTrianglesLeft;
	context.m_triangleIsAvailable[undoData.m_triangleIndex] = 1;

	// Remove any new vertexes that were added to the partition by this triangle.
	if (undoData.m_numNewVertexes > 0)
	{
		// It's VERY IMPORTANT that the vertices be removed in ascending numerical order!  Otherwise, errors can occur.
		// e.g. when removing [5,4] from the array [1,2,3,4,5,6], removing the 4 would yield [1,2,3,5,5,6], and removing
		// the five would yield [1,2,3,4,6,6].  The last two entries would then be removed, leaving an unwanted 4 and 
		// discarding the 6 forever.
		// qsort() is probably overkill for sorting 1-3 elements, but this isn't performance-critical code.
		qsort((uint32_t*)undoData.m_newVertexes, undoData.m_numNewVertexes, sizeof(uint32_t), _edgeGeomIsEqualUnsigned);

		// Iterate over the vertexes in this partition.  When we find the verts added by this triangle,
		// overwrite them with an element from the end of the array.  When we're done, we'll qsort the
		// array.
		uint32_t numToFind = undoData.m_numNewVertexes;
		EDGEASSERT(numToFind <= 3);
		bool findMe[3] = {true,true,true};
		for(uint32_t iVertex=0; iVertex<context.m_numVertexesInPartition && numToFind > 0; ++iVertex)
		{
			for(uint32_t iNewVertex=0; iNewVertex<undoData.m_numNewVertexes; ++iNewVertex)
			{
				if (findMe[iNewVertex] && context.m_vertexesInPartition[iVertex] == undoData.m_newVertexes[iNewVertex])
				{
					context.m_vertexesInPartition[iVertex] = context.m_vertexesInPartition[context.m_numVertexesInPartition-(iNewVertex+1)];
					findMe[iNewVertex] = false;
					--numToFind;
				}
			}
		}
		EDGEASSERT(numToFind == 0);
		context.m_numVertexesInPartition -= undoData.m_numNewVertexes;
		context.m_numBlendedVertexesInPartition -= undoData.m_numNewBlendedVertexes;
		qsort(context.m_vertexesInPartition, context.m_numVertexesInPartition, sizeof(uint32_t), _edgeGeomIsEqualUnsigned);
	}

	// Remove any new matrices that were added to the partition by this triangle
	if (undoData.m_numNewMatrices > 0)
	{
		// See comment in above block about why it's necessary to sort the matrices indices before removing them!
		qsort((int32_t*)undoData.m_newMatrices, undoData.m_numNewMatrices, sizeof(int32_t), _edgeGeomIsEqualInt);

		// Iterate over the matrices in this partition.  When we find the matrices added by this triangle,
		// overwrite them with an element from the end of the array.  When we're done, we'll qsort the
		// array.
		uint32_t numToFind = undoData.m_numNewMatrices;
		EDGEASSERT(numToFind <= 12);
		bool findMe[12] = {true,true,true, true,true,true, true,true,true, true,true,true};
		for(uint32_t iMatrix=0; iMatrix<context.m_numMatricesInPartition && numToFind > 0; ++iMatrix)
		{
			for(uint32_t iNewMatrix=0; iNewMatrix<undoData.m_numNewMatrices; ++iNewMatrix)
			{
				if (findMe[iNewMatrix] && context.m_matricesInPartition[iMatrix] == undoData.m_newMatrices[iNewMatrix])
				{
					context.m_matricesInPartition[iMatrix] = context.m_matricesInPartition[context.m_numMatricesInPartition-(iNewMatrix+1)];
					findMe[iNewMatrix] = false;
					--numToFind;
				}
			}
		}
		EDGEASSERT(numToFind == 0);
		context.m_numMatricesInPartition -= undoData.m_numNewMatrices;
		qsort(context.m_matricesInPartition, context.m_numMatricesInPartition, sizeof(int32_t), _edgeGeomIsEqualInt);
	}
	
	return true;
}

//-------------------
/// This function returns a sharing score that is somehow representative of the degree 
/// to which this face is expensive to add to a partition.  Thus, lower values are 
/// better, and zero is as good as you can get (the only impact on the partition is 
/// adding 3 indexes to the triangle list).  Also, this takes into account the number 
/// of indexes being capped at 32k, which can happen when sharing is high and triangle list is long.
/// If the faceIndex is 0xffffffff, just measure the existing partition and do NOT count the new face.
/// This particular implementation tries not to measure the compressed index table, for performance
/// reasons, thus there is some possibility of failure due to inaccurate estimation.  A 
/// constant might need to be tweaked to estimate higher.
static float ScoreTriangle(EdgeGeomPartitionerContext &context, const EdgeGeomPartitionerInput &dataIn,
						   uint32_t triangleIndex,	uint32_t *actualBytesUsed, bool exactCalc)
{
	bool alreadyHasMatrices = context.m_matricesInPartition != NULL && context.m_numMatricesInPartition > 0;
	
	// remember the min and max matrices we need for the partition, so we can predict the buffer usage
	int32_t minMatrix = alreadyHasMatrices ? context.m_matricesInPartition[0] : INT_MAX;
	int32_t maxMatrix = alreadyHasMatrices ? context.m_matricesInPartition[context.m_numMatricesInPartition-1] : 0;

	uint32_t newNumTriangles = context.m_numTrianglesInPartition + (triangleIndex != 0xffffffff ? 1 : 0);
	uint32_t numNewVertexes = 0;
	uint32_t numNewMatrices = 0; // NOT a unique count!
	uint32_t numNewBlending = 0;
	int32_t newMatrices[12]; // indexes of any new matrices we're adding to the partition, so we don't have to look for them again below. May include duplicates!
	uint32_t numMatricesToUpload = alreadyHasMatrices ? (maxMatrix-minMatrix+1) : 0; // Very conservative estimate; updated below
	if (triangleIndex!=0xffffffff) // if triangleIndex *is* -1, we simply score the existing partition and don't add a new triangle.
	{
		for (uint32_t iTriVertex=0; iTriVertex<3; ++iTriVertex)
		{
			const uint32_t vertexIndex = dataIn.m_triangleList[triangleIndex*3+iTriVertex];
			if (!bsearch(&vertexIndex, context.m_vertexesInPartition, context.m_numVertexesInPartition, sizeof(uint32_t), _edgeGeomIsEqualUnsigned))
			{
				numNewVertexes++;  // ding for having to add a new vertex

				// find out if any of these new vertexes are blending.
				if (dataIn.m_blendedVertexIndexes && bsearch(&vertexIndex, dataIn.m_blendedVertexIndexes, dataIn.m_numBlendedVertexes, sizeof(uint32_t), _edgeGeomIsEqualUnsigned))
				{
					numNewBlending++;
				}

				// and because this vertex is not known, we must see
				// how expensive its additional skinning requirements
				// will be.  If we already had the vertex, we know
				// that all its matrices have been accounted for.
				if (context.m_matricesInPartition != NULL)  // don't bother keeping track of matrices if there's nowhere to store them
				{
					for (uint32_t iVertMatrix=0; iVertMatrix<kEdgeGeomNumInputBonesPerVertex; ++iVertMatrix)
					{
						int const matrixIndex = dataIn.m_skinningMatrixIndexesPerVertex[vertexIndex*kEdgeGeomNumInputBonesPerVertex+iVertMatrix];
						if (matrixIndex!=-1 && !bsearch(&matrixIndex, context.m_matricesInPartition, context.m_numMatricesInPartition, sizeof(int32_t), _edgeGeomIsEqualInt))
						{
							newMatrices[numNewMatrices++] = matrixIndex;
							if (minMatrix>matrixIndex)   // track the highest and lowest indexes for later
								minMatrix = matrixIndex;
							if (maxMatrix<matrixIndex)
								maxMatrix = matrixIndex;
						}
					}
				}
			}
		}

		 // update our estimate in case minMatrix and maxMatrix have changed
		if (numNewMatrices > 0)
			numMatricesToUpload = (maxMatrix-minMatrix+1);

		// Reject this triangle if the partition uses too many (>256) matrices.  If the numMatricesToUpload is
		// already 256 matrices or fewer, we're fine.  Otherwise, we need to do a more precise test.
		if (numNewMatrices > 0 && numMatricesToUpload > 256)
		{
			numNewMatrices = _edgeGeomSortUniqueArrayInt(newMatrices, numNewMatrices); // eliminate duplicates in newMatrices;
			// Create a temporary sorted copy of the partition's matrices, including the new ones added by the current triangle
			uint32_t tempNumMatrices = context.m_numMatricesInPartition + numNewMatrices;
			int32_t *tempMatrixIndexes = (int32_t*)edgeGeomAlloc(tempNumMatrices*sizeof(int32_t));
			memcpy(tempMatrixIndexes, context.m_matricesInPartition, context.m_numMatricesInPartition*sizeof(int32_t));
			memcpy(tempMatrixIndexes + context.m_numMatricesInPartition, newMatrices, numNewMatrices*sizeof(int32_t));
			qsort(tempMatrixIndexes, tempNumMatrices, sizeof(int32_t), _edgeGeomIsEqualInt);

			// Skinning matrices are uploaded to the SPUs in two contiguous chunks, combined into one flat array.
			// This is a compromise between uploading the entire range from minMatrix to maxMatrix (most of which
			// may be unused by the current partition) and having a separate DMA for each individual matrix.
			// walk the unique matrices looking for the biggest gap
			int32_t biggestGap = 0;
			//uint32_t indexToGap = 0;  // this is where in tmpMatrixIndexes that the biggest gap was detected, NOT the matrix index itself
			for (uint32_t iMatrix=1; iMatrix<tempNumMatrices; iMatrix++)
			{
				const int32_t gap = tempMatrixIndexes[iMatrix] - tempMatrixIndexes[iMatrix-1] - 1;
				if (gap>biggestGap)
				{
					biggestGap = gap;
					//indexToGap = iMatrix;
				}
			}
			edgeGeomFree(tempMatrixIndexes);

			// numMatricesToUpload can now be an exact count
			numMatricesToUpload = (maxMatrix-minMatrix+1) - biggestGap;
			if (numMatricesToUpload > 256) // only 256 matrices can be uploaded with each job
			{
				return FLT_MAX;
			}
		}		
	}

	// Final space requirements should be based on vertex counts that
	// have been rounded up to the nearest multiple of 8.
	uint32_t newNumVertexesRounded = (context.m_numVertexesInPartition + numNewVertexes + 7) & ~7;

	// cap the triangle list at 32k
	uint32_t indexesSize = 0;
	uint32_t indexesTempSize = 0;
	uint32_t outIndexesSize = (sizeof(uint16_t) * newNumTriangles*3 + 15) & ~15;  // output index size will always be 2 bytes/index
	switch (dataIn.m_indexListFlavor)
	{
		case kIndexesU16TriangleListCW:
		case kIndexesU16TriangleListCCW:
		{
			// Uncompressed input indexes are the same size as the output indexes (2 bytes/index)
			indexesSize = outIndexesSize;
			indexesTempSize = 0; // no temporary space required
			break;
		}
			
		case kIndexesCompressedTriangleListCW:
		case kIndexesCompressedTriangleListCCW:
		{
			// this is refined over successive calls, reset per partition and every few triangles
			if (exactCalc)
			{
				// Temporarily add this triangle to the partition's triangle list, so we can compress
				// it and see how large it is.  We don't actually bump up the triangle count, though.
				if (triangleIndex!=0xffffffff)
				{
					context.m_trianglesInPartition[context.m_numTrianglesInPartition*3+0] = dataIn.m_triangleList[triangleIndex*3+0];
					context.m_trianglesInPartition[context.m_numTrianglesInPartition*3+1] = dataIn.m_triangleList[triangleIndex*3+1];
					context.m_trianglesInPartition[context.m_numTrianglesInPartition*3+2] = dataIn.m_triangleList[triangleIndex*3+2];
				}

				// Allocate an array to reorderthe triangle list into.
				uint32_t *tmpTris = (uint32_t*)edgeGeomAlloc(newNumTriangles*3*sizeof(uint32_t));

				// reorder the triangles first
				if (dataIn.m_cacheOptimizerCallback != NULL)
				{
					dataIn.m_cacheOptimizerCallback(context.m_trianglesInPartition, newNumTriangles, dataIn.m_cacheOptimizerUserData, tmpTris);
				}
				else
				{
					memcpy(tmpTris, context.m_trianglesInPartition, newNumTriangles*3*sizeof(uint32_t));
				}

				// make the index buffer now, so we can get the size of it
				EdgeGeomIndexesSizes measuredSizes;
				_edgeGeomMeasureCompressedIndexTable(tmpTris, newNumTriangles, dataIn.m_indexListFlavor, &measuredSizes);
				indexesSize = measuredSizes.m_inputSize;
				indexesTempSize = measuredSizes.m_maxTempSize;
				
				// Store the exact measurement results to help make future estimates more accurate
				context.m_lastExactIndexesSize = indexesSize;
				context.m_lastExactIndexesTempSize = indexesTempSize;
				context.m_lastNumTriangles = newNumTriangles;

				edgeGeomFree(tmpTris);
			}
			else
			{
				// Estimate the compressed size based on a hypothetical worst-case scenario: a tessellated plane, in which
				// every lower-left triangle is drawn, and then every upper-right triangle.  This has the following characteristics:
				// - 2 bits per triangle for the 2-bit table
				// - 3 bits per triangle for the 1-bit table (no vertex reuse between triangles)
				// - maximum compressed delta size of log2(numVerticesPerPartition)
				// - numTriangles*3/2 deltas in the delta table (the first numTriangles*3/2 indices will be sequential; the rest
				//   are non-sequential, and will be stored as compressed deltas.
				// We also re-use the results of the most recent exact measurement, if any, to provide a more accurate baseline
				// measurement.
				float numTrianglesToEstimate = (float)(newNumTriangles - context.m_lastNumTriangles);
				float estimatedBitsPerTriangle = 2 + 3 + 1.5f*logf((float)(context.m_numVertexesInPartition + numNewVertexes))/logf(2.0f);
				float numBitsEstimated = estimatedBitsPerTriangle * numTrianglesToEstimate;
				indexesSize = context.m_lastExactIndexesSize + (uint32_t)((numBitsEstimated+7.0f)/8.0f);
				// worst-case, the temporary usage is the size of the decompressed triangles, plus the size of the decompressed deltas,
				// plus the 2-bit stream itself.
				// So, 2*sizeof(uint16_t) + 0.25 * numTriangles
				indexesTempSize = context.m_lastExactIndexesTempSize + (uint32_t)(12.25f * (float)numTrianglesToEstimate);
			}
			break;
		}
		
		default:
			EDGEERROR_F(); // unknown index list flavor
	}

	// Calculate stream description size.  We use a very conservative
	// estimate here, because doing this right would involve knowing
	// full details of all relevant vertex formats.  If we assume
	// every attribute is fixed-point, then each SPU stream description
	// will be (2*8*attributeCount + 16) bytes. RSX stream descritions are
	// smaller (8*attributeCount + 16), since they can't include fixed-point attributes
	const uint32_t inputStreamDescriptionSize = (2*8*dataIn.m_numInputAttributes + 16);
	const uint32_t outputStreamDescriptionSize = (8*dataIn.m_numOutputAttributes + 16);

	// restrict the partition to 16k max blend shape size.  For stream description and fixed point offset
	// size estimates, we use the very conservative guess that every input attribute is fixed-point and blended.
	bool partitionIsBlending = (context.m_numBlendedVertexesInPartition > 0);
	const uint32_t blendShapeHeaderSize = 4*4*dataIn.m_numInputAttributes + inputStreamDescriptionSize + 32;
	const uint32_t blendShapeDeltaTableSize = (dataIn.m_deltaStreamVertexStride * newNumVertexesRounded + 0xF) & ~0xF;
	// If the partition is blending, there's a hard limit of 2048 vertices in the partition due to the format of the
	// compressed blended vertex run table (which uses 11 bits to store the index of the beginning of each run.  It's
	// unlikely that this ceiling will be reached in practice; this test is just for safety.
	if (partitionIsBlending && newNumVertexesRounded > 2048)
	{
		return FLT_MAX;
	}
	// Use a conservative estimate for the size of the compressed run table.  TODO: the run table will be decompressed
	// in-place to a size of newNumVertexesRounded*sizeof(uint16_t) bytes (rounded up to the nearest qword).  Right now
	// we simply assume that the decompressed table will fit in the I/O buffer, since blend shapes streams are generally smaller
	// than the compressed vertex streams that they're overwriting.  But if we wanted to be 100% safe, we should take the
	// decompressed run table size into account when computing the final score.  Regardless, the fully-compressed blend
	// shape stream can't be larger than 16K (the maximize size of a single DMA operation).
	const uint32_t blendShapeRunTableSize = ((newNumVertexesRounded/2 + 1) * sizeof(uint16_t) + 0xF) & ~0xF;
	const uint32_t blendShapeSize =  partitionIsBlending ? (blendShapeHeaderSize + blendShapeDeltaTableSize + blendShapeRunTableSize) : 0;

	// restrict the total space allowed to the i/o buffer + scratch buffer size
	// TODO: if numOutAttributes > numInputAttributes, why would we need extra uniform tables?
	const uint32_t maxAttributes = (dataIn.m_numInputAttributes > dataIn.m_numOutputAttributes) ?
		dataIn.m_numInputAttributes : dataIn.m_numOutputAttributes; 
	const uint32_t scratchBufferSize = 16*edgeGeomGetScratchBufferSizeInQwords(maxAttributes, newNumVertexesRounded);

	// It is an error if the total number of uniform tables (including the extra table) is greater than 16.
	if (maxAttributes + 1 > 16)
	{
		EDGEERROR_F();
	}

	uint32_t userIoBufferUsed = 0;
	// If there is USER-SPECIFIED data or code going into the SPU (outside of the partition), put its size here.
	if (dataIn.m_customDataSizeCallback != NULL)
	{
		EdgeGeomPartitionElementCounts partitionContents;
		partitionContents.m_numTriangles = context.m_numTrianglesInPartition;
		partitionContents.m_numVertexes = context.m_numVertexesInPartition;
		partitionContents.m_numMatrices = context.m_numMatricesInPartition;
		partitionContents.m_numBlendedVertexes = context.m_numBlendedVertexesInPartition;
		userIoBufferUsed = dataIn.m_customDataSizeCallback(partitionContents);
	}
	bool userBufferUsedAfterIndexDecompression = false;

	// If we're using a single-bone skinning flavor, the input buffer size required per vertex will be smaller.
	bool useSingleBoneSkinning = (dataIn.m_skinningFlavor == kSkinSingleBoneNoScaling) || (dataIn.m_skinningFlavor == kSkinSingleBoneUniformScaling)
		|| (dataIn.m_skinningFlavor == kSkinSingleBoneNonUniformScaling);
	unsigned const bytesPerSkinnedVertex = useSingleBoneSkinning ? 1 : 2*context.m_numOutputBonesPerVertex;

	uint32_t inputBufferUsed = userIoBufferUsed + sizeof(EdgeGeomSpuConfigInfo) + sizeof(EdgeGeomViewportInfo) + sizeof(EdgeGeomLocalToWorldMatrix);
	inputBufferUsed += inputStreamDescriptionSize + outputStreamDescriptionSize;
	if (numMatricesToUpload > 0)
	{
		// Add 127 for alignment slop.
		const uint32_t kMatrixSize = (dataIn.m_skinningMatrixFormat == kMatrix3x4RowMajor) ? 3*4*sizeof(float) : 4*4*sizeof(float);
		inputBufferUsed += numMatricesToUpload * kMatrixSize + 127;  // this is a slight overestimation, but fast enough for partitioning.
		inputBufferUsed += bytesPerSkinnedVertex*newNumVertexesRounded;  // count skinning info per vertex
	}
	const uint32_t inputVertexStreamSize = (newNumVertexesRounded * dataIn.m_inputVertexStride[0] + 15) & ~15;	
	const uint32_t secondaryInputVertexStreamSize = (newNumVertexesRounded * dataIn.m_inputVertexStride[1] + 15) & ~15;
	inputBufferUsed += 4*4*dataIn.m_numInputAttributes; // for input fixed-point offsets (we assume all input attributes are fixed-point)
	inputBufferUsed += EDGEMAX(secondaryInputVertexStreamSize + inputVertexStreamSize, blendShapeSize);  // pick whichever is bigger, on the off-chance somebody uses low-grade base models and high-grade blend shapes
	inputBufferUsed += indexesSize;
	inputBufferUsed = (inputBufferUsed+127) & ~127;  // align to 128 bytes

	uint32_t indexTempUsed = userBufferUsedAfterIndexDecompression ? userIoBufferUsed : 0;
	indexTempUsed += outputStreamDescriptionSize; //output stream description will still be in memory when indexes are decompressed
	indexTempUsed += indexesTempSize;
	indexTempUsed = (indexTempUsed+127) & ~127;  // align to 128 bytes

	//We need a quadword to accept a read from VRAM to make sure that
	//data output to vram finishes being written before we fill the
	//command buffer hole.
	uint32_t const vramSyncSize = 16;
	
	uint32_t const commandBufferHoleSize = edgeGeomGetCommandBufferHoleSize(dataIn.m_numOutputAttributes, newNumTriangles*3, dataIn.m_customCommandBufferHoleSizeCallback);
	uint32_t outputBufferUsed = userIoBufferUsed + commandBufferHoleSize + vramSyncSize;
	outputBufferUsed += 128; // the hole contents on the SPU must be at the same relative 128-byte alignment with the hole itself, so we may need some extra padding.
							 // See edgeGeomBeginCommandBufferHole().
	outputBufferUsed += outputStreamDescriptionSize;  // the input stream description has been overwritten before the output stage
	outputBufferUsed += outIndexesSize;
	outputBufferUsed += (newNumVertexesRounded * dataIn.m_outputVertexStride + 15) & ~15;
	outputBufferUsed += 16; // workaround: the runtime vertex compression code can overwrite up to 16 bytes past the end of the output array.  Until fixed, we need to at least account for it.
	outputBufferUsed = (outputBufferUsed+127) & ~127;  // align to 128 bytes

	*actualBytesUsed = EDGEMAX(EDGEMAX(outputBufferUsed, inputBufferUsed), indexTempUsed);  // take the high-water mark of SPU memory as the rule
	const float ioBufferScore = *actualBytesUsed / (float)kMaxIoBufferSize;
	const float indexScore = indexesSize / 32768.0f;
	const float blendShapeScore = blendShapeSize / 16384.0f;

	// The scratch buffer has no strict maximum capacity; it's okay for the scratch buffer to intrude into whatever
	// space the current I/O buffer isn't using.
	const float scratchBufferScore = (scratchBufferSize + *actualBytesUsed) / (float)(kMaxIoScratchTotalSize);

	// take the worst of the scores and return it
	const float finalScore = EDGEMAX(EDGEMAX(ioBufferScore, scratchBufferScore), EDGEMAX(indexScore, blendShapeScore));
	if (finalScore <= 1.0f)
	{
		context.m_lastInOutScore = ioBufferScore;
		context.m_lastScratchScore = scratchBufferScore;
		context.m_lastIndexesScore = indexScore;
		context.m_lastBlendShapeScore = blendShapeScore;
	}
	return finalScore;
}

//-------------------

static void FinalizePartition(const EdgeGeomPartitionerInput &dataIn, EdgeGeomPartitionerContext &context,
							  EdgeGeomPartitionerOutput *dataOut)
{
	// finally, score the ending partition exactly
	uint32_t actualBytes = 0;
	float finalTriangleScore = FLT_MAX;
	do
	{
		finalTriangleScore = ScoreTriangle(context, dataIn, 0xFFFFFFFF, &actualBytes, true);
		g_exactScoreCount++;
		g_regularScoreCount++;
		if (finalTriangleScore > 1.0f)
		{
			bool removed = RemoveLastTriangleFromPartition(context);
			EDGEASSERT(removed); // if the stack is every empty when we try to remove, something is very wrong...
		}
	}
	while (finalTriangleScore > 1.0f);
	// If this trigger fires and you are using index compression, please see notes above about adjusting the threshold for running the exact calculation.
	EDGEASSERT(finalTriangleScore<=1.0f); // the partition should have been valid before we tried to add the last triangle...why is it bad now?

	// copy this finished partition to the dataOut structure and reset for another pass.
	dataOut->m_numTrianglesPerPartition[dataOut->m_numPartitions] = context.m_numTrianglesInPartition;
	dataOut->m_ioBufferSizePerPartition[dataOut->m_numPartitions] = actualBytes;
	dataOut->m_numPartitions++;

	// go through each triangle and copy the indexes from the source triangle list to the output one
	const uint32_t numTrianglesInOutput = dataIn.m_numTriangles - context.m_numTrianglesLeft - context.m_numTrianglesInPartition;
	memcpy(dataOut->m_triangleListOut + numTrianglesInOutput*3, context.m_trianglesInPartition, context.m_numTrianglesInPartition*3*sizeof(uint32_t));

#if 0 // debug code
	printf("segment %3d scores: I/O=%5.3f scratch=%5.3f indexes=%5.3f blend=%5.3f\n", dataOut->m_numPartitions,
		context.m_lastInOutScore, context.m_lastScratchScore, context.m_lastIndexesScore, context.m_lastBlendShapeScore);
#endif
}

//-------------------

static void RemapAllTriangleLists(EdgeGeomPartitionerOutput *dataOut)
{
	// Determine the total combined number of triangles in all partitions
	uint32_t numTotalTriangles = 0;
	for(uint32_t iPartition=0; iPartition<dataOut->m_numPartitions; ++iPartition)
	{
		numTotalTriangles += dataOut->m_numTrianglesPerPartition[iPartition];
	}

	// Generate a sorted table of unique vertex indexes in each partition.  We store them
	// in one flat array, analagous to the existing triangle lists.
	uint32_t *numUniqueVertexesPerPartition = (uint32_t*)edgeGeomAlloc(dataOut->m_numPartitions * sizeof(uint32_t));
	uint32_t *sortedUniqueIndexesPerPartition = (uint32_t*)edgeGeomAlloc(numTotalTriangles*3*sizeof(uint32_t));
	memcpy(sortedUniqueIndexesPerPartition, dataOut->m_triangleListOut, numTotalTriangles*3*sizeof(uint32_t));
	uint32_t *nextTriangleList = sortedUniqueIndexesPerPartition;
	uint32_t numTotalUniqueVertexes = 0; // Somewhat misleading name -- this is the sum of the entries in numUniqueVertexes, which will be >= numVertexes on account of duplicates.
	for(uint32_t iPartition=0; iPartition<dataOut->m_numPartitions; ++iPartition)
	{
		const uint32_t numUniqueVertexes = _edgeGeomSortUniqueArrayUnsigned(nextTriangleList,
			dataOut->m_numTrianglesPerPartition[iPartition]*3);
		numUniqueVertexesPerPartition[iPartition] = numUniqueVertexes;
		numTotalUniqueVertexes += numUniqueVertexes;
		// Advance pointer to next partition
		nextTriangleList += dataOut->m_numTrianglesPerPartition[iPartition]*3;
	}

	// Now we can generate the per-partition vertex remapping tables, which are also stored as a flat
	// array (see a pattern?)
	uint32_t *originalOrderLookupPerPartition = (uint32_t*)edgeGeomAlloc(numTotalUniqueVertexes*sizeof(uint32_t));
	memset(originalOrderLookupPerPartition, 0xFF, numTotalUniqueVertexes*sizeof(uint32_t));
	const uint32_t *sortedUniqueIndexes = sortedUniqueIndexesPerPartition;
	uint32_t *originalOrderLookup = originalOrderLookupPerPartition;
	uint32_t *triangleList = dataOut->m_triangleListOut;
	for(uint32_t iPartition=0; iPartition<dataOut->m_numPartitions; ++iPartition)
	{
		const uint32_t numTriangles = dataOut->m_numTrianglesPerPartition[iPartition];
		const uint32_t numUniqueVertexes = numUniqueVertexesPerPartition[iPartition];
		uint32_t largestUniqueIndex = sortedUniqueIndexes[numUniqueVertexes-1];

		// Remap this partition's triangle list in-place.  The reverse mapping (from each new vertex index
		// to its corresponding original index) will be stored in the originalOrderLookup table.
		_edgeGeomRemapTriangleList(triangleList, numTriangles, largestUniqueIndex, originalOrderLookup);

		// Advance pointers to the next partition's arrays
		triangleList += numTriangles*3;
		sortedUniqueIndexes += numTriangles*3;
		originalOrderLookup += numUniqueVertexes;
	}

	edgeGeomFree(sortedUniqueIndexesPerPartition);
	dataOut->m_originalVertexIndexesPerPartition = originalOrderLookupPerPartition;
	dataOut->m_numUniqueVertexesPerPartition = numUniqueVertexesPerPartition;
}

//-------------------

void edgeGeomPartitioner(const EdgeGeomPartitionerInput &dataIn, EdgeGeomPartitionerOutput *dataOut)
{
#if defined(_M_IX86)
	const uint32_t oldFpMask = _controlfp(0, 0);
	_controlfp(_PC_24, _MCW_PC);
#endif
	
	// handle the trivial return first--no triangles, so no partitions
	if (dataIn.m_numTriangles == 0)
	{
		dataOut->m_numTrianglesPerPartition = 0;
		dataOut->m_numPartitions = 0;
		dataOut->m_triangleListOut = 0;
		dataOut->m_ioBufferSizePerPartition = 0;
		return;
	}

	// Initialize partitioner context
	EdgeGeomPartitionerContext context;
	memset(&context, 0, sizeof(EdgeGeomPartitionerContext));

	// Initialize the outgoing data structure.
	dataOut->m_numPartitions            = 0;
	dataOut->m_numTrianglesPerPartition = (uint32_t*)edgeGeomAlloc(dataIn.m_numTriangles * sizeof(uint32_t));  // waaaay overestimate, but better than two passes
	dataOut->m_triangleListOut          = (uint32_t*)edgeGeomAlloc(dataIn.m_numTriangles*3 * sizeof(uint32_t));
	dataOut->m_ioBufferSizePerPartition = (uint32_t*)edgeGeomAlloc(dataIn.m_numTriangles * sizeof(uint32_t));  // ditto.

	// dump the data into the array now that it's the right size
	context.m_highestVertexIndex = FindHighestVertexIndex(dataIn.m_triangleList, dataIn.m_numTriangles);
	context.m_highestMatrixIndex = FindHighestMatrixIndex(dataIn.m_triangleList, dataIn.m_numTriangles, dataIn.m_skinningMatrixIndexesPerVertex); // -1 if no skinning
	FindAdjacentTriangles(context, dataIn.m_triangleList, dataIn.m_numTriangles);

	// each entry in this array is either zero or one, depending on
	// whether the triangle is available (1) for placing in the
	// current partition or not (0).
	context.m_triangleIsAvailable = (int8_t*)edgeGeomAlloc(dataIn.m_numTriangles * sizeof(int8_t));
	memset(context.m_triangleIsAvailable, 1, dataIn.m_numTriangles * sizeof(int8_t));  // set all faces as 'available'

	// this is the list of faces, vertexes, and matrices that are
	// currently in the growing partition. The matrix list may be a
	// null array if no matrices are present, for simplicity.
	context.m_trianglesInPartition = (uint32_t*)edgeGeomAlloc(dataIn.m_numTriangles * 3 * sizeof(uint32_t));
	context.m_vertexesInPartition  = (uint32_t*)edgeGeomAlloc((context.m_highestVertexIndex+1) * sizeof(uint32_t));  
	context.m_matricesInPartition  = (context.m_highestMatrixIndex != -1) ? (int32_t*)edgeGeomAlloc((context.m_highestMatrixIndex+1)*sizeof(int32_t)) : NULL;

	// this is the stack of triangle undo data.  It is cleared whenever an exact-mode measurement is made successfully
	// (because at that point, you know for sure all the triangles you have will fit).
	context.m_triangleUndoStackCapacity = 10000; // arbitrary, but it seems highly unlikely that you'd fit this many triangles in a partition.
	context.m_triangleUndoStack = (EdgeGeomTriangleUndoData*)edgeGeomAlloc(context.m_triangleUndoStackCapacity * sizeof(EdgeGeomTriangleUndoData));
	context.m_triangleUndoStackTop = 0;

	// Determine how many skinning bones to expect per vertex
	switch(dataIn.m_skinningFlavor)
	{
	case kSkinSingleBoneNoScaling:
	case kSkinSingleBoneUniformScaling:
	case kSkinSingleBoneNonUniformScaling:
		// INTENTIONAL FALL-THROUGH! single-bone skinning does actually output 4 bones; it's fixed up as a postprocess.
	case kSkinNone:
	default:
		context.m_numOutputBonesPerVertex = 4;
		break;
	}

	// Okay, start filling partitions until we run out of faces.
	context.m_numTrianglesLeft = dataIn.m_numTriangles;

	// The algorithm for partitioning is very simple.  A partition is
	// created by taking whatever the first available triangle is.
	//int32_t bestActualBytes = -1;
	g_exactScoreCount = 0;
	g_regularScoreCount = 0;
	while (context.m_numTrianglesLeft > 0)
	{
		// create a new partition, since there's no triangles in the current one.
		if (context.m_numTrianglesInPartition==0)
		{
			// find a face that hasn't been issued yet
			const int32_t startTriangle = FindFirstAvailableTriangle(context, dataIn.m_numTriangles, dataIn.m_triangleCentroids);
			EDGEASSERT(startTriangle!=-1);  // if this triggers, it means numTrianglesLeft does not agree with the trianglesAvailable array

			// check that this face will fit.  If it doesn't, it means this triangle can't possibly be processed by Edge.
			// This is, of course, a serious problem, and one we'd like to hear about if this assert fires.
			uint32_t actualBytes = 0;
			float triangleScore = ScoreTriangle(context, dataIn, startTriangle, &actualBytes, false);
			g_regularScoreCount++;
			if (triangleScore > 1.0f)
			{
				printf("SERIOUS ERROR: one-triangle partition won't fit in SPU local store! Contact the Playstation Edge developers!\n");
				EDGEASSERT(triangleScore <= 1.0f); // effectively, assert(false)
				break;
			}

			// assign the initial face
			AssignTriangleToPartition(context, startTriangle, dataIn.m_triangleList, dataIn.m_skinningMatrixIndexesPerVertex, dataIn.m_blendedVertexIndexes,
				dataIn.m_numBlendedVertexes, dataIn.m_triangleCentroids);
		}

		// search and remember the best next available triangle
		uint32_t bestTriangle = 0xffffffff;
		float bestScore = FLT_MAX;
		float bestDistanceSq = FLT_MAX;
		for (uint32_t iVertex=0; iVertex<context.m_numVertexesInPartition; iVertex++)
		{
			// consider every face that uses each vertex in our partition.
			const uint32_t currentVertex = context.m_vertexesInPartition[iVertex];
			for (uint32_t iRelatedTriangle=context.m_adjacencyDataStarts[currentVertex]; iRelatedTriangle<context.m_adjacencyDataStarts[currentVertex+1]; iRelatedTriangle++)
			{
				const uint32_t triangleIndex = context.m_adjacentTrianglesPerVertex[iRelatedTriangle];
				if (!context.m_triangleIsAvailable[triangleIndex])  // If the face is already assigned, skip it.
					continue;

				// calculate the fullness score of the partition
				// assuming we added this new face
				uint32_t actualBytes = 0;
				float triangleScore = ScoreTriangle(context, dataIn, triangleIndex, &actualBytes, false);
				g_regularScoreCount++;

				// If we have triangle centroids, calculate the
				// distanceSquared of this triangle from partition
				// centroid
				float distSq = FLT_MAX;
				if (dataIn.m_triangleCentroids)
				{
					const float deltaX = dataIn.m_triangleCentroids[triangleIndex*3+0] - context.m_partitionCentroid[0];
					const float deltaY = dataIn.m_triangleCentroids[triangleIndex*3+1] - context.m_partitionCentroid[1];
					const float deltaZ = dataIn.m_triangleCentroids[triangleIndex*3+2] - context.m_partitionCentroid[2];
					distSq = deltaX*deltaX + deltaY*deltaY + deltaZ*deltaZ;
				}

				// either the triangle is judged better, or it's the same score but closer...
				if (triangleScore > bestScore || (triangleScore == bestScore && distSq >= bestDistanceSq))
					continue;

				bestScore = triangleScore;
				bestTriangle = triangleIndex;
				//bestActualBytes = actualBytes;
				bestDistanceSq = distSq;
			}
		}

		// if there are NO triangles that are related to the existing
		// partition and haven't been assigned, pick a non-connected triangle.
		if (context.m_numTrianglesLeft > 0 && bestTriangle==0xffffffff)
		{
			// find a triangle that hasn't been issued yet. This function will pick the nearest triangle to the partition centroid
			// if triangle centroids are available; otherwise, it picks the first available triangle it finds.
			int32_t newTriangleIndex = FindFirstAvailableTriangle(context, dataIn.m_numTriangles, dataIn.m_triangleCentroids);
			EDGEASSERT(newTriangleIndex!=-1);  // if this triggers, it means numTrianglesLeft does not agree with the trianglesAvailable array

			// check that this face will fit
			uint32_t actualBytes = 0;
			float triangleScore = ScoreTriangle(context, dataIn, newTriangleIndex, &actualBytes, false);
			g_regularScoreCount++;

			// note, here we DO NOT BOTHER checking the distance from partition centroid, because
			// the FindFirstAvailableTriangle does that for us.  Minor simplification.
			if (triangleScore < bestScore)  
			{
				bestScore = triangleScore;
				bestTriangle = newTriangleIndex;
				//bestActualBytes = actualBytes;
			}
		}

		// Make sure the best match we found *really* fits.
		if (bestScore > 1.0f && bestTriangle != 0xFFFFFFFF)
		{
			uint32_t actualBytes = 0;
			const float exactTriangleScore = ScoreTriangle(context, dataIn, bestTriangle, &actualBytes, true);
			
			// The inexact calculation should always be more conservative than the exact one, by design.  If this
			// assert triggers, please inform the Edge developers.  Beyond that, it is perfectly safe to disable this
			// assert in production builds; the undo stack will take care of any partitions that end up too full.
			//if (bestScore < exactTriangleScore)
			//{
			//	DumpPartitionerInputToFile(dataIn, "EdgePartitionerInputDump.c");
			//}
			//EDGEASSERT(bestScore >= exactTriangleScore);

			if (exactTriangleScore <= 1.0f)  // only assign this the lower value IF it is a valid triangle.
			{
				bestScore = exactTriangleScore;
				context.m_triangleUndoStackTop = 0; // clear the undo stack, since this is a known good configuration.
			}
			g_exactScoreCount++;  // count how many times we make this call
			g_regularScoreCount++;
		}

		// since we know that the last test of the partition was under
		// the limit, all we need to do is see if the next triangle
		// puts us OVER the limit.  If so, make the partition w/o the
		// next triangle.
		if (bestScore <= 1.0f)
		{
			AssignTriangleToPartition(context, bestTriangle, dataIn.m_triangleList, dataIn.m_skinningMatrixIndexesPerVertex,
									  dataIn.m_blendedVertexIndexes, dataIn.m_numBlendedVertexes, dataIn.m_triangleCentroids);
		}
		else  // too large... save this partition and start a new one
		{
			// If this assert triggers, it means we failed to add *any* triangles to the partition,
			// but there are still some unassigned triangles remaining.  In release builds, this will lead
			// to an infinite loop.  This is very, very bad.  Contact the Edge developers!
			if (context.m_numTrianglesInPartition == 0 && context.m_numTrianglesLeft > 0)
			{
				printf("SERIOUS ERROR: %d triangles could not be assigned to any partition!  Contact the Playstation Edge developers!\n",
					context.m_numTrianglesLeft);
				EDGEASSERT(context.m_numTrianglesLeft == 0); // effectively, assert(0)
				break; // escape the infinite loop, at least
			}

			FinalizePartition(dataIn, context, dataOut);

			// reset and start fresh
			context.m_numTrianglesInPartition = 0;
			context.m_numVertexesInPartition = 0;
			context.m_numMatricesInPartition = 0;
			context.m_numBlendedVertexesInPartition = 0;
			context.m_lastExactIndexesSize = 0;
			context.m_lastExactIndexesTempSize = 0;
			context.m_lastNumTriangles = 0;
			context.m_triangleUndoStackTop = 0;
			// note, we SPECIFICALLY DO NOT clear the partition
			// centroid, because it's better to pick up where we left
			// off, or as nearly as possible, rather than pick some
			// arbitrary starting point every time.  The fact that the
			// number of faces in the partition has been reset means
			// it only affects the very first triangle selection. Very
			// clean!
		}
	}

	// finish the last partition by copying it to the final partition space
	if (context.m_numTrianglesInPartition)
	{
		FinalizePartition(dataIn, context, dataOut);
	}

	// Release the memory used by the context structure
	edgeGeomFree(context.m_adjacencyDataStarts);
	edgeGeomFree(context.m_adjacentTrianglesPerVertex);
	edgeGeomFree(context.m_triangleIsAvailable);
	edgeGeomFree(context.m_trianglesInPartition);
	edgeGeomFree(context.m_vertexesInPartition);
	edgeGeomFree(context.m_matricesInPartition);
	edgeGeomFree(context.m_triangleUndoStack);

	// Run the kcache optimizer to generate the final index order.
	if (dataIn.m_cacheOptimizerCallback != NULL)
	{
		uint32_t *currentTriangles = dataOut->m_triangleListOut;
		for(uint32_t iPartition=0; iPartition<dataOut->m_numPartitions; ++iPartition)
		{
			uint32_t numTriangles = dataOut->m_numTrianglesPerPartition[iPartition];

			// Call K-Cache reordering code
			uint32_t *trianglesCopy = (uint32_t*)edgeGeomAlloc(numTriangles*3*sizeof(uint32_t));
			memcpy(trianglesCopy, currentTriangles, numTriangles*3*sizeof(uint32_t));

			dataIn.m_cacheOptimizerCallback(trianglesCopy, numTriangles, dataIn.m_cacheOptimizerUserData, currentTriangles);
			edgeGeomFree(trianglesCopy);

			currentTriangles += numTriangles*3;
		}
	}

	// Remap the output triangles to use the new local ordering of vertexes within each partition.
	// Also generates the vertex order mapping table to determine which original vertex each remapped
	// vertex was copied from.
	RemapAllTriangleLists(dataOut);

#if defined(_M_IX86)
	_controlfp(oldFpMask, 0xffffffff);  // set everything back the way it was
#endif
}

//-------------------
